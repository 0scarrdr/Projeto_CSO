# SOAR Test Suite

Este diretÃ³rio contÃ©m a suÃ­te completa de testes para o sistema SOAR (Security Orchestration, Automation and Response).

## ğŸ“‹ VisÃ£o Geral dos Testes

### Estrutura dos Testes

```
tests/
â”œâ”€â”€ test_core.py          # Testes unitÃ¡rios do nÃºcleo do sistema
â”œâ”€â”€ test_detection.py     # Testes do componente de detecÃ§Ã£o
â”œâ”€â”€ test_analysis.py      # Testes do componente de anÃ¡lise
â”œâ”€â”€ test_response.py      # Testes do componente de resposta
â”œâ”€â”€ test_prediction.py    # Testes do componente de prediÃ§Ã£o
â”œâ”€â”€ test_integration.py   # Testes de integraÃ§Ã£o end-to-end
â”œâ”€â”€ test_api.py          # Testes da API REST
â”œâ”€â”€ run_tests.py         # Executor principal de testes
â”œâ”€â”€ load_test.py         # Testes de carga e performance
â””â”€â”€ README.md           # Esta documentaÃ§Ã£o
```

## ğŸš€ Como Executar os Testes

### PrÃ©-requisitos

1. **Python 3.8+** instalado
2. **DependÃªncias instaladas**:
   ```bash
   pip install pytest pytest-asyncio pytest-cov rich aiohttp fastapi
   ```

3. **SOAR API em execuÃ§Ã£o** (para testes de API e integraÃ§Ã£o):
   ```bash
   cd src/soar
   python server.py
   ```

### ExecuÃ§Ã£o BÃ¡sica

#### Executar Todos os Testes
```bash
# Do diretÃ³rio raiz do projeto
python tests/run_tests.py
```

#### Executar Testes UnitÃ¡rios Apenas
```bash
python tests/run_tests.py --unit
```

#### Executar Testes de IntegraÃ§Ã£o
```bash
python tests/run_tests.py --integration
```

#### Executar Testes de API
```bash
python tests/run_tests.py --api
```

#### Executar Testes de Performance
```bash
python tests/run_tests.py --performance
```

#### Executar Smoke Tests (RÃ¡pidos)
```bash
python tests/run_tests.py --smoke
```

### Usando Pytest Diretamente

#### Executar Testes EspecÃ­ficos
```bash
# Testes de um componente especÃ­fico
pytest tests/test_core.py -v

# Testes de uma classe especÃ­fica
pytest tests/test_detection.py::TestThreatDetector -v

# Testes de um mÃ©todo especÃ­fico
pytest tests/test_core.py::TestIncidentHandler::test_handle_incident_success -v
```

#### Com Cobertura de CÃ³digo
```bash
pytest --cov=src/soar --cov-report=html
```

#### Com RelatÃ³rio Detalhado
```bash
pytest -v --tb=long --durations=10
```

## ğŸ“Š Tipos de Testes

### 1. Testes UnitÃ¡rios (`test_*.py`)
- **PropÃ³sito**: Testar componentes individuais isoladamente
- **Cobertura**:
  - `test_core.py`: IncidentHandler e componentes principais
  - `test_detection.py`: ThreatDetector e classificaÃ§Ã£o
  - `test_analysis.py`: IncidentAnalyzer e avaliaÃ§Ã£o de risco
  - `test_response.py`: AutomatedResponder e playbooks
  - `test_prediction.py`: ThreatPredictor e forecasting

### 2. Testes de IntegraÃ§Ã£o (`test_integration.py`)
- **PropÃ³sito**: Testar interaÃ§Ã£o entre componentes
- **CenÃ¡rios**:
  - Processamento completo de incidentes
  - Fluxo detecÃ§Ã£o â†’ anÃ¡lise â†’ resposta â†’ prediÃ§Ã£o
  - CenÃ¡rios de ataque complexos
  - Tratamento de erros e recuperaÃ§Ã£o

### 3. Testes de API (`test_api.py`)
- **PropÃ³sito**: Testar endpoints REST da API
- **Cobertura**:
  - Endpoints bÃ¡sicos (`/`, `/health`, `/status`)
  - Processamento de incidentes (`POST /incidents`)
  - MÃ©tricas e KPIs
  - ValidaÃ§Ã£o de dados e tratamento de erros

### 4. Testes de Performance
- **Load Testing** (`load_test.py`): Testa performance sob carga
- **Benchmarking**: Valida targets de performance do enunciado

## ğŸ¯ Targets de Performance

Os testes validam os seguintes targets especificados no enunciado:

### Response Metrics
- âœ… **Time to detect**: < 1 minuto
- âœ… **Time to respond**: < 5 minutos
- âœ… **False positive rate**: < 0.1%
- âœ… **Successful containment**: > 95%
- âœ… **Recovery accuracy**: > 99%
- âœ… **Evidence preservation**: 100%

### Analysis Metrics
- âœ… **Classification accuracy**: > 95%
- âœ… **Risk assessment accuracy**: > 90%
- âœ… **Prediction accuracy**: > 85%
- âœ… **Pattern recognition rate**: > 90%
- âœ… **Impact assessment accuracy**: > 85%
- âœ… **Recovery optimization**: > 80%

## ğŸ“ˆ RelatÃ³rios e Resultados

### RelatÃ³rio de Testes
ApÃ³s execuÃ§Ã£o, Ã© gerado automaticamente:
- **Arquivo**: `test_results.json`
- **ConteÃºdo**: Resultados detalhados, mÃ©tricas, tempos de execuÃ§Ã£o

### Cobertura de CÃ³digo
```bash
pytest --cov=src/soar --cov-report=html
```
Gera relatÃ³rio HTML em `htmlcov/index.html`

### Testes de Carga
```bash
python tests/load_test.py --requests 1000 --concurrency 50
```

## ğŸ”§ ConfiguraÃ§Ã£o dos Testes

### Arquivo `pytest.ini`
ConfiguraÃ§Ãµes globais do pytest:
- Paths de teste
- Marcadores personalizados
- RelatÃ³rios de cobertura
- ConfiguraÃ§Ãµes asyncio

### Fixtures Comuns
- `sample_event`: Evento de seguranÃ§a de exemplo
- `sample_incident`: Incidente processado de exemplo
- `mock_incident_handler`: Mock do handler principal

## ğŸš¨ Tratamento de Erros

### Testes que Falham
- **Verificar dependÃªncias**: Todos os imports devem funcionar
- **API nÃ£o executando**: Para testes de API, iniciar servidor primeiro
- **Timeouts**: Ajustar timeouts em `pytest.ini` se necessÃ¡rio

### Debugging
```bash
# Executar com debug detalhado
pytest -v -s --tb=long

# Parar no primeiro erro
pytest --maxfail=1

# Executar testes especÃ­ficos que falharam
pytest --lf
```

## ğŸ“ Adicionando Novos Testes

### Estrutura de Teste UnitÃ¡rio
```python
import pytest
from soar.component import ComponentClass

class TestComponentClass:
    def test_method_name(self):
        # Arrange
        component = ComponentClass()

        # Act
        result = component.method_name()

        # Assert
        assert result == expected_value
```

### Testes AssÃ­ncronos
```python
@pytest.mark.asyncio
async def test_async_method(self):
    # Para mÃ©todos async
    result = await component.async_method()
    assert result.success
```

### Testes de IntegraÃ§Ã£o
```python
@pytest.mark.integration
def test_component_integration(self):
    # Testar interaÃ§Ã£o entre componentes
    detector = ThreatDetector()
    analyzer = IncidentAnalyzer()

    incident = detector.classify(event)
    analysis = analyzer.analyze(incident)

    assert analysis.risk_score > 0
```

## ğŸ‰ Boas PrÃ¡ticas

1. **Isolamento**: Cada teste deve ser independente
2. **Nomenclatura**: `test_*` para funÃ§Ãµes, `Test*` para classes
3. **Fixtures**: Usar fixtures para setup/teardown comum
4. **Marcadores**: Usar marcadores para categorizar testes
5. **AsserÃ§Ãµes**: Ser especÃ­fico nas asserÃ§Ãµes
6. **Cobertura**: Manter cobertura > 80%

## ğŸ“ Suporte

Para dÃºvidas sobre os testes:
1. Verificar logs detalhados com `-v`
2. Usar `--tb=long` para tracebacks completos
3. Consultar `test_results.json` para anÃ¡lise de falhas
4. Verificar cobertura com `--cov-report=html`
